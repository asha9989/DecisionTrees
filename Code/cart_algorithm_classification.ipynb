{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cart_algorithm_classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Classification decision tree using *CART* algorithm for binary target variable and numeric input features"
      ],
      "metadata": {
        "id": "FljDhnc9nyZD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pa \n",
        "import numpy as np \n",
        "from collections import Counter\n",
        "\n",
        "class Node: \n",
        "    \n",
        "    def __init__(\n",
        "        self, \n",
        "        Y: list,\n",
        "        X: pa.DataFrame,\n",
        "        minSamplesForStop=None,\n",
        "        maxDepth=None,\n",
        "        depth=None,\n",
        "        nodeType=None,\n",
        "        rule=None\n",
        "    ):\n",
        "        \n",
        "        self.Y = Y \n",
        "        self.X = X\n",
        "\n",
        "        # stopping criterion and their default values\n",
        "        self.minSamplesForStop = minSamplesForStop if minSamplesForStop else 20\n",
        "        self.maxDepth = maxDepth if maxDepth else 5\n",
        "\n",
        "        # Default depth of current node \n",
        "        self.depth = depth if depth else 0\n",
        "\n",
        "        # Feature extraction\n",
        "        self.features = list(self.X.columns)\n",
        "\n",
        "        # setting the type of the node \n",
        "        self.nodeType = nodeType if nodeType else 'root'\n",
        "\n",
        "        # splitting rule\n",
        "        self.rule = rule if rule else \"\"\n",
        "\n",
        "        self.counts = Counter(Y)\n",
        "\n",
        "        # calculate Gini Impurity\n",
        "        self.giniImpurity = self.getGini()\n",
        "\n",
        "        # Sorting the counts and saving the final prediction of the node \n",
        "        sortedCounts = list(sorted(self.counts.items(), key=lambda item: item[1]))\n",
        "\n",
        "        # Getting the last item\n",
        "        ylast = None\n",
        "        if len(sortedCounts) > 0:\n",
        "            ylast = sortedCounts[-1][0]\n",
        "\n",
        "        # Leaf Node to predict the class with the highest number of samples from a class\n",
        "        self.ylast = ylast \n",
        "        \n",
        "        self.n = len(Y)\n",
        "\n",
        "        # set default values to left and right nodes\n",
        "        self.left = None \n",
        "        self.right = None \n",
        "\n",
        "        # Default values for splits\n",
        "        self.bestFeature = None \n",
        "        self.bestValue = None \n",
        "\n",
        "    @staticmethod\n",
        "    def calculateGiniImpurity(y1Count: int, y2Count: int) -> float:\n",
        "        \n",
        "        if y1Count is None:\n",
        "            y1Count = 0\n",
        "\n",
        "        if y2Count is None:\n",
        "            y2Count = 0\n",
        "        \n",
        "        # Calculate total observations\n",
        "        totalCount = y1Count + y2Count\n",
        "        \n",
        "        # If totalCount = 0 then the samples are from same class. Hence Gini impurity is zero\n",
        "        if totalCount == 0:\n",
        "            return 0.0\n",
        "\n",
        "        # Calculate the probability of the binary classes\n",
        "        class1 = y1Count / totalCount\n",
        "        class2 = y2Count / totalCount\n",
        "        \n",
        "        # Calculate Gini impurity\n",
        "        gini = 1 - (class1 ** 2 + class2 ** 2)        \n",
        "        \n",
        "        return gini\n",
        "\n",
        "    @staticmethod\n",
        "    def ma(x: np.array, window: int) -> np.array:       \n",
        "        return np.convolve(x, np.ones(window), 'valid') / window\n",
        "\n",
        "    def getGini(self):        \n",
        "        # Get Gini impurity for binary classes 0 or 1\n",
        "        y1_count, y2_count = self.counts.get(0, 0), self.counts.get(1, 0)       \n",
        "        return self.calculateGiniImpurity(y1_count, y2_count)\n",
        "\n",
        "    def bestSplit(self) -> tuple:        \n",
        "        # Split data\n",
        "        df = self.X.copy()\n",
        "        df['Y'] = self.Y\n",
        "        \n",
        "        baseGini = self.getGini()       \n",
        "        maxGain = 0       \n",
        "        bestFeature = None\n",
        "        bestValue = None\n",
        "\n",
        "        for feature in self.features:\n",
        "            # Droping missing values\n",
        "            Xdf = df.dropna().sort_values(feature)            \n",
        "            xmeans = self.ma(Xdf[feature].unique(), 2)\n",
        "\n",
        "            for value in xmeans:\n",
        "                # Spliting the dataset \n",
        "                leftCounts = Counter(Xdf[Xdf[feature]<value]['Y'])\n",
        "                rightCounts = Counter(Xdf[Xdf[feature]>=value]['Y'])\n",
        "\n",
        "                # Getting the Y distribution\n",
        "                y0Left, y1Left, y0Right, y1Right = leftCounts.get(0, 0), leftCounts.get(1, 0), rightCounts.get(0, 0), rightCounts.get(1, 0)\n",
        "\n",
        "                # Getting gini impurities for left and right impurities\n",
        "                giniLeft = self.calculateGiniImpurity(y0Left, y1Left)\n",
        "                giniRight = self.calculateGiniImpurity(y0Right, y1Right)\n",
        "              \n",
        "                totalLeft = y0Left + y1Left\n",
        "                totalRight = y0Right + y1Right\n",
        "                total = totalLeft + totalRight\n",
        "\n",
        "                # Calculating the weights for each of the nodes\n",
        "                leftWeight = totalLeft / total\n",
        "                rightWeight = totalRight / total\n",
        "               \n",
        "                giniWeight = leftWeight * giniLeft + rightWeight * giniRight\n",
        "               \n",
        "                giniGain = baseGini - giniWeight\n",
        "\n",
        "                # Check if it's the best split\n",
        "                if giniGain > maxGain:\n",
        "                    bestFeature = feature\n",
        "                    bestValue = value                    \n",
        "                    maxGain = giniGain\n",
        "\n",
        "        return (bestFeature, bestValue)\n",
        "\n",
        "    def growTree(self):        \n",
        "        df = self.X.copy()\n",
        "        df['Y'] = self.Y\n",
        "       \n",
        "        if (self.depth < self.maxDepth) and (self.n >= self.minSamplesForStop):\n",
        "\n",
        "            # Getting the best split \n",
        "            bestFeature, bestValue = self.bestSplit()\n",
        "\n",
        "            if bestFeature is not None:\n",
        "                # Saving the best split to the current node \n",
        "                self.bestFeature = bestFeature\n",
        "                self.bestValue = bestValue\n",
        "\n",
        "                # Getting the left and right nodes\n",
        "                left_df, right_df = df[df[bestFeature]<=bestValue].copy(), df[df[bestFeature]>bestValue].copy()\n",
        "\n",
        "                # Creating the left and right nodes\n",
        "                left = Node(\n",
        "                    left_df['Y'].values.tolist(), \n",
        "                    left_df[self.features], \n",
        "                    depth=self.depth + 1, \n",
        "                    maxDepth=self.maxDepth, \n",
        "                    minSamplesForStop=self.minSamplesForStop, \n",
        "                    nodeType='left_node',\n",
        "                    rule=f\"{bestFeature} <= {round(bestValue, 3)}\"\n",
        "                    )\n",
        "\n",
        "                self.left = left \n",
        "                self.left.growTree()\n",
        "\n",
        "                right = Node(\n",
        "                    right_df['Y'].values.tolist(), \n",
        "                    right_df[self.features], \n",
        "                    depth=self.depth + 1, \n",
        "                    maxDepth=self.maxDepth, \n",
        "                    minSamplesForStop=self.minSamplesForStop,\n",
        "                    nodeType='right_node',\n",
        "                    rule=f\"{bestFeature} > {round(bestValue, 3)}\"\n",
        "                    )\n",
        "\n",
        "                self.right = right\n",
        "                self.right.growTree()\n",
        "    \n",
        "    def predict(self, X:pa.DataFrame):       \n",
        "        predictions = []\n",
        "\n",
        "        for index, x in X.iterrows():\n",
        "            values = {}\n",
        "            for feature in self.features:\n",
        "                values.update({feature: x.loc[feature]})\n",
        "        \n",
        "            predictions.append(self.predictObservations(values))\n",
        "        \n",
        "        return predictions\n",
        "\n",
        "    def predictObservations(self, values: dict) -> int:       \n",
        "        currentNode = self\n",
        "        while  currentNode is not None and currentNode.bestFeature is not None and currentNode.depth < currentNode.maxDepth:\n",
        "            bestFeature = currentNode.bestFeature\n",
        "            bestValue = currentNode.bestValue\n",
        "\n",
        "            if currentNode.n < currentNode.minSamplesForStop:\n",
        "                break \n",
        "\n",
        "            if (values.get(bestFeature) < bestValue):\n",
        "                if self.left is not None:\n",
        "                    currentNode = currentNode.left\n",
        "            else:\n",
        "                if self.right is not None:\n",
        "                    currentNode = currentNode.right\n",
        "            \n",
        "        return  currentNode.ylast   \n",
        "\n",
        "    "
      ],
      "metadata": {
        "id": "9-N7l1o1oP6n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Util: \n",
        " def convertToBinaryArr(inputArr, matchWithOne):\n",
        "      binaryArr =[]\n",
        "      for target in inputArr:\n",
        "        if target == matchWithOne:\n",
        "          binaryArr.append(1)\n",
        "        else:\n",
        "          binaryArr.append(0)\n",
        "\n",
        "      return binaryArr   \n",
        "\n",
        " def calculateAccuracy(predictedLabels, targetLabels):\n",
        "      count=0\n",
        "      accuracy=0        \n",
        "      for i in range(len(predictedLabels)):\n",
        "          if targetLabels[i]== predictedLabels[i]:\n",
        "            count +=1\n",
        "      return (count/len(predictedLabels))*100 \n",
        "\n",
        "\n",
        " def getPerformanceMetrics(targetLabels,predictedLabels,tpLable):\n",
        "      tp=0\n",
        "      tn=0\n",
        "      fp=0\n",
        "      fn=0\n",
        "      for i in range(len(predictedLabels)):\n",
        "        if targetLabels[i]== predictedLabels[i]:\n",
        "          if targetLabels[i]==tpLable:\n",
        "            tp +=1\n",
        "          else:\n",
        "            tn +=1\n",
        "        else:\n",
        "           if targetLabels[i]==tpLable:\n",
        "             fn +=1\n",
        "           else:\n",
        "             fp +=1\n",
        "      accuracy = (tp+tn)/(tp+fn+fp+tn)\n",
        "      recall = tp/(tp+fn)\n",
        "      specificity = tn/(fp+tn)\n",
        "      precision = tp/(tp+fp)\n",
        "      f1 = 2 *((precision * recall)/(precision + recall))\n",
        "      return  (accuracy, recall,specificity, precision, f1)   "
      ],
      "metadata": {
        "id": "LH2-zWwo4gLb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Applying above algorithm for Heart dataset"
      ],
      "metadata": {
        "id": "ZGDbIzwvCM7Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from warnings import filterwarnings\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score,precision_score,recall_score,f1_score\n",
        "\n",
        "#read the sample data from CSV file\n",
        "dataFile=pd.read_csv(\"heart.csv\")\n",
        "\n",
        "#split the data to train and test by using cross validation\n",
        "train, test = train_test_split(dataFile, test_size=0.3 , random_state=1)\n",
        "\n",
        "\n",
        "#drop the column alp2 from training set as it is used for prediction\n",
        "X_train = train.drop(\"a1p2\",axis=1)\n",
        "y_train = train[\"a1p2\"]\n",
        "X_test = test.drop(\"a1p2\",axis=1)\n",
        "y_test = test[\"a1p2\"]\n",
        "\n",
        "\n",
        "col_header = X_train.columns\n",
        "scaler = StandardScaler()\n",
        "X_train_transform = scaler.fit_transform(X_train)\n",
        "X_test_transform = scaler.transform(X_test)\n",
        "\n",
        "X_train = pd.DataFrame(X_train_transform, columns = col_header)\n",
        "X_test = pd.DataFrame(X_test_transform, columns = col_header)\n",
        "trainLabels = Util.convertToBinaryArr(y_train, 1)\n",
        "testLabels =  Util.convertToBinaryArr(y_test, 1)\n",
        "\n",
        "root = Node(trainLabels, X_train, maxDepth=3, minSamplesForStop=100)  \n",
        "root.growTree()\n",
        "\n",
        "xtrainClone = X_train.copy()\n",
        "xtrainClone['predicted'] = root.predict(xtrainClone)\n",
        "\n",
        "#calculate accuracy for train data\n",
        "trainAccuracy = Util.calculateAccuracy(np.array(xtrainClone['predicted']), trainLabels) \n",
        "print('Training Accuracy: %f' % trainAccuracy)\n",
        "\n",
        "xtestClone = X_test.copy()\n",
        "xtestClone['predicted'] = root.predict(xtestClone)\n",
        "#calculate accuracy for test data\n",
        "testAccuracy = Util.calculateAccuracy(np.array(xtestClone['predicted']), testLabels) \n",
        "print('Testing Accuracy: %f' % testAccuracy)\n",
        "\n",
        "accuracy, recall,specificity, precision, f1 = Util.getPerformanceMetrics(testLabels,np.array(xtestClone['predicted']),1)\n",
        "\n",
        "print('Performance Metrics of Test Data : Accuracy : %0.2f , Recall : %0.2f ,Specificity: %0.2f , Precision : %0.2f, F1 Score: %0.2f' % (accuracy*100 , recall*100 ,specificity*100 , precision*100 , f1*100 ) )\n",
        "print('----------------------------------------------------')\n",
        "\n",
        "#compare performance metrics with scikit learn library by training using scikit\n",
        "dTree = DecisionTreeClassifier(criterion = 'gini', max_depth = 3, random_state=1)\n",
        "dTree.fit(X_train, trainLabels)\n",
        "y_predict = dTree.predict(X_test)\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(testLabels,y_predict).ravel()\n",
        "\n",
        "print('Performance Metrics of Test Data with scikit : Accuracy : %0.2f , Recall : %0.2f ,Specificity: %0.2f , Precision : %0.2f, F1 Score: %0.2f' % (accuracy_score(testLabels, y_predict)*100 , recall_score(testLabels, y_predict)*100 ,(tn / (tn+fp))*100 , precision_score(testLabels, y_predict)*100 , f1_score(testLabels, y_predict)*100 ) )\n",
        "print('----------------------------------------------------')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yRmvvYcqCT7q",
        "outputId": "bad26513-6da8-4861-ae78-224e6b3ac1f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy: 78.835979\n",
            "Testing Accuracy: 70.370370\n",
            "Performance Metrics of Test Data : Accuracy : 70.37 , Recall : 74.47 ,Specificity: 64.71 , Precision : 74.47, F1 Score: 74.47\n",
            "----------------------------------------------------\n",
            "Performance Metrics of Test Data with scikit : Accuracy : 76.54 , Recall : 82.98 ,Specificity: 67.65 , Precision : 78.00, F1 Score: 80.41\n",
            "----------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Improve performance on Heart DataSet by changing the cross validation and dropping a feature"
      ],
      "metadata": {
        "id": "GiYs4m_jZI4I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from warnings import filterwarnings\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score,precision_score,recall_score,f1_score\n",
        "\n",
        "#read the sample data from CSV file\n",
        "dataFile=pd.read_csv(\"heart.csv\")\n",
        "\n",
        "#drop and check \n",
        "dataFile = dataFile.drop('thal',axis=1)\n",
        "\n",
        "\n",
        "#split the data to train and test by using cross validation\n",
        "train, test = train_test_split(dataFile, test_size=0.33 , random_state=1)\n",
        "\n",
        "\n",
        "#drop the column alp2 from training set as it is used for prediction\n",
        "X_train = train.drop(\"a1p2\",axis=1)\n",
        "y_train = train[\"a1p2\"]\n",
        "X_test = test.drop(\"a1p2\",axis=1)\n",
        "y_test = test[\"a1p2\"]\n",
        "\n",
        "\n",
        "col_header = X_train.columns\n",
        "scaler = StandardScaler()\n",
        "X_train_transform = scaler.fit_transform(X_train)\n",
        "X_test_transform = scaler.transform(X_test)\n",
        "\n",
        "X_train = pd.DataFrame(X_train_transform, columns = col_header)\n",
        "X_test = pd.DataFrame(X_test_transform, columns = col_header)\n",
        "trainLabels = Util.convertToBinaryArr(y_train, 1)\n",
        "testLabels =  Util.convertToBinaryArr(y_test, 1)\n",
        "\n",
        "root = Node(trainLabels, X_train, maxDepth=3, minSamplesForStop=100)  \n",
        "root.growTree()\n",
        "\n",
        "xtrainClone = X_train.copy()\n",
        "xtrainClone['predicted'] = root.predict(xtrainClone)\n",
        "\n",
        "#calculate accuracy for train data\n",
        "trainAccuracy = Util.calculateAccuracy(np.array(xtrainClone['predicted']), trainLabels) \n",
        "print('Training Accuracy: %f' % trainAccuracy)\n",
        "\n",
        "xtestClone = X_test.copy()\n",
        "xtestClone['predicted'] = root.predict(xtestClone)\n",
        "#calculate accuracy for test data\n",
        "testAccuracy = Util.calculateAccuracy(np.array(xtestClone['predicted']), testLabels) \n",
        "print('Testing Accuracy: %f' % testAccuracy)\n",
        "\n",
        "accuracy, recall,specificity, precision, f1 = Util.getPerformanceMetrics(testLabels,np.array(xtestClone['predicted']),1)\n",
        "\n",
        "print('Performance Metrics of Test Data : Accuracy : %0.2f , Recall : %0.2f ,Specificity: %0.2f , Precision : %0.2f, F1 Score: %0.2f' % (accuracy*100 , recall*100 ,specificity*100 , precision*100 , f1*100 ) )\n",
        "print('----------------------------------------------------')\n",
        "\n",
        "#compare performance metrics with scikit learn library by training using scikit\n",
        "dTree = DecisionTreeClassifier(criterion = 'gini', max_depth = 3, random_state=1)\n",
        "dTree.fit(X_train, trainLabels)\n",
        "y_predict = dTree.predict(X_test)\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(testLabels,y_predict).ravel()\n",
        "\n",
        "print('Performance Metrics of Test Data with scikit : Accuracy : %0.2f , Recall : %0.2f ,Specificity: %0.2f , Precision : %0.2f, F1 Score: %0.2f' % (accuracy_score(testLabels, y_predict)*100 , recall_score(testLabels, y_predict)*100 ,(tn / (tn+fp))*100 , precision_score(testLabels, y_predict)*100 , f1_score(testLabels, y_predict)*100 ) )\n",
        "print('----------------------------------------------------')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tmwtrNPzZVi9",
        "outputId": "d28c8c57-4bb2-4884-ccbd-46ed15d10659"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy: 75.000000\n",
            "Testing Accuracy: 75.555556\n",
            "Performance Metrics of Test Data : Accuracy : 75.56 , Recall : 80.00 ,Specificity: 70.00 , Precision : 76.92, F1 Score: 78.43\n",
            "----------------------------------------------------\n",
            "Performance Metrics of Test Data with scikit : Accuracy : 81.11 , Recall : 88.00 ,Specificity: 72.50 , Precision : 80.00, F1 Score: 83.81\n",
            "----------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Apply CART algorithm for credit card data"
      ],
      "metadata": {
        "id": "X1V70FF0YYLT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score,precision_score,recall_score,f1_score\n",
        "\n",
        "credit_card_data=pd.read_csv(\"credit.csv\")\n",
        "for feature in credit_card_data.columns: # Loop through all columns in the dataframe\n",
        "    if credit_card_data[feature].dtype == 'object': # Only apply for columns with categorical strings\n",
        "        credit_card_data[feature] = pd.Categorical(credit_card_data[feature])# Replace strings with an integer\n",
        "replaceCategorical = {\n",
        "               \"checking_balance\":     {\"< 0 DM\": 1, \"1 - 200 DM\": 2 ,\"> 200 DM\": 3 ,\"unknown\":-1},\n",
        "                \"credit_history\": {\"critical\": 1, \"poor\":2 , \"good\": 3, \"very good\": 4,\"perfect\": 5},\n",
        "                 \"savings_balance\": {\"< 100 DM\": 1, \"100 - 500 DM\":2 , \"500 - 1000 DM\": 3, \"> 1000 DM\": 4,\"unknown\": -1},\n",
        "                 \"employment_duration\":     {\"unemployed\": 1, \"< 1 year\": 2 ,\"1 - 4 years\": 3 ,\"4 - 7 years\": 4 ,\"> 7 years\": 5},\n",
        "                \"phone\":     {\"no\": 1, \"yes\": 2 },\n",
        "                 \"default\":     {\"no\": 0, \"yes\": 1 } \n",
        "                    }\n",
        "oneHotEncodingCols=[\"purpose\",\"housing\",\"other_credit\",\"job\"]\n",
        "\n",
        "\n",
        "credit_card_data=credit_card_data.replace(replaceCategorical)\n",
        "credit_card_data=pd.get_dummies(credit_card_data, columns=oneHotEncodingCols)\n",
        "X = credit_card_data.drop(\"default\" , axis=1)\n",
        "y = credit_card_data.pop(\"default\")\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.30, random_state=1)\n",
        "\n",
        "root = Node(y_train, X_train, maxDepth=3, minSamplesForStop=100)  \n",
        "root.growTree()\n",
        "\n",
        "train_clone = X_train.copy()\n",
        "train_clone['predicted'] = root.predict(train_clone)\n",
        "\n",
        "#calculate accuracy for train data\n",
        "trainAccuracy = Util.calculateAccuracy(np.array(train_clone['predicted']), np.array(y_train))\n",
        "print('Training Accuracy: %f' % trainAccuracy)\n",
        "\n",
        "text_clone = X_test.copy()\n",
        "text_clone['predicted'] = root.predict(text_clone)\n",
        "#calculate accuracy for test data\n",
        "testAccuracy = Util.calculateAccuracy(np.array(text_clone['predicted']), np.array(y_test)) \n",
        "print('Testing Accuracy: %f' % testAccuracy)\n",
        "\n",
        "accuracy, recall,specificity, precision, f1 = Util.getPerformanceMetrics(np.array(y_test),np.array(text_clone['predicted']),1)\n",
        "\n",
        "print('Performance Metrics of Test Data of credit card dataset : Accuracy : %0.2f , Recall : %0.2f ,Specificity: %0.2f , Precision : %0.2f, F1 Score: %0.2f' % (accuracy*100 , recall*100 ,specificity*100 , precision*100 , f1*100 ) )\n",
        "print('----------------------------------------------------')\n",
        "#compare performance metrics with scikit learn library by training using scikit\n",
        "dTree = DecisionTreeClassifier(criterion = 'gini', max_depth = 3, random_state=1)\n",
        "dTree.fit(X_train, y_train)\n",
        "y_predict = dTree.predict(X_test)\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(y_test,y_predict).ravel()\n",
        "\n",
        "print('Performance Metrics of Test Data with scikit : Accuracy : %0.2f , Recall : %0.2f ,Specificity: %0.2f , Precision : %0.2f, F1 Score: %0.2f' % (accuracy_score(y_test, y_predict)*100 , recall_score(y_test, y_predict)*100 ,tn / (tn+fp)*100 , precision_score(y_test, y_predict)*100 , f1_score(y_test, y_predict)*100 ) )\n",
        "print('----------------------------------------------------')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efm3z4JPYcvJ",
        "outputId": "4dc3127c-0fae-4927-893a-e9da7a7e6d37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy: 74.857143\n",
            "Testing Accuracy: 75.000000\n",
            "Performance Metrics of Test Data of credit card dataset : Accuracy : 75.00 , Recall : 46.51 ,Specificity: 86.45 , Precision : 57.97, F1 Score: 51.61\n",
            "----------------------------------------------------\n",
            "Performance Metrics of Test Data with scikit : Accuracy : 74.33 , Recall : 46.51 ,Specificity: 85.51 , Precision : 56.34, F1 Score: 50.96\n",
            "----------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Apply CART algorithm for voice data"
      ],
      "metadata": {
        "id": "SYuy9aUHDl4o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score,precision_score,recall_score,f1_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "\n",
        "voice_data = pd.read_csv(r\"voice.csv\",header = 0)\n",
        "#voice_data.head()\n",
        "\n",
        "#check for missing or null values\n",
        "voice_data.isnull().sum()\n",
        "\n",
        "colname=voice_data.columns\n",
        "\n",
        "#converting categorical values to numerical values using label encoder\n",
        "lable_encoder=preprocessing.LabelEncoder()\n",
        "\n",
        "for x in colname:\n",
        "    voice_data[x]=lable_encoder.fit_transform(voice_data[x])\n",
        "\n",
        "#voice_data.head()\n",
        "\n",
        "X=voice_data.values[:,:-1]\n",
        "Y=voice_data.values[:,-1]\n",
        "Y=Y.astype(int)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X)\n",
        "X=scaler.transform(X)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3,\n",
        "random_state=10)\n",
        "\n",
        "colname = colname[:-1]\n",
        "X_train = pd.DataFrame(X_train, columns = colname)\n",
        "X_test = pd.DataFrame(X_test, columns =colname)\n",
        "\n",
        "root = Node(y_train, X_train, maxDepth=3, minSamplesForStop=100)  \n",
        "root.growTree()\n",
        "\n",
        "train_clone = X_train.copy()\n",
        "train_clone['predicted'] = root.predict(train_clone)\n",
        "\n",
        "#calculate accuracy for train data\n",
        "trainAccuracy = Util.calculateAccuracy(np.array(train_clone['predicted']), np.array(y_train))\n",
        "print('Training Accuracy: %f' % trainAccuracy)\n",
        "\n",
        "\n",
        "test_clone = X_test.copy()\n",
        "test_clone['predicted'] = root.predict(test_clone)\n",
        "#calculate accuracy for test data\n",
        "testAccuracy = Util.calculateAccuracy(np.array(test_clone['predicted']), y_test) \n",
        "print('Testing Accuracy: %f' % testAccuracy)\n",
        "\n",
        "accuracy, recall,specificity, precision, f1 = Util.getPerformanceMetrics(y_test,np.array(test_clone['predicted']),1)\n",
        "\n",
        "print('Performance Metrics of Test Data : Accuracy : %0.2f , Recall : %0.2f ,Specificity: %0.2f , Precision : %0.2f, F1 Score: %0.2f' % (accuracy*100 , recall*100 ,specificity*100 , precision*100 , f1*100 ) )\n",
        "\n",
        "print('----------------------------------------------------')\n",
        "#compare performance metrics with scikit learn library by training using scikit\n",
        "dTree = DecisionTreeClassifier(criterion = 'gini', max_depth = 3, random_state=1)\n",
        "dTree.fit(X_train, y_train)\n",
        "y_predict = dTree.predict(X_test)\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(y_test,y_predict).ravel()\n",
        "\n",
        "print('Performance Metrics of Test Data with scikit : Accuracy : %0.2f , Recall : %0.2f ,Specificity: %0.2f , Precision : %0.2f, F1 Score: %0.2f' % (accuracy_score(y_test, y_predict)*100 , recall_score(y_test, y_predict)*100 ,(tn / (tn+fp))*100 , precision_score(y_test, y_predict)*100 , f1_score(y_test, y_predict)*100 ) )\n",
        "\n",
        "print('----------------------------------------------------')\n",
        "randomForest = RandomForestClassifier()\n",
        "randomForest =randomForest.fit(X_train, y_train)\n",
        "y_rand = randomForest.predict(X_test)\n",
        "tn, fp, fn, tp = confusion_matrix(y_test,y_rand).ravel()\n",
        "print('Performance Metrics of Test Data with scikit for Random Forest: Accuracy : %0.2f , Recall : %0.2f , Specificity: %0.2f , Precision : %0.2f, F1 Score: %0.2f' % (accuracy_score(y_test, y_rand)*100 , recall_score(y_test, y_rand)*100 , (tn / (tn+fp))*100 , precision_score(y_test, y_rand)*100 , f1_score(y_test, y_rand)*100 ) )\n",
        "print('----------------------------------------------------')\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "\n",
        "baggingClassifier1 = BaggingClassifier(base_estimator=dTree)\n",
        "\n",
        "baggingClassifier1 = baggingClassifier1.fit(X_train, y_train)\n",
        "y_bagging = baggingClassifier1.predict(X_test)\n",
        "tn, fp, fn, tp = confusion_matrix(y_test,y_bagging).ravel()\n",
        "print('Performance Metrics of Test Data with scikit for Bagging Classifier: Accuracy : %0.2f , Recall : %0.2f , Specificity: %0.2f , Precision : %0.2f, F1 Score: %0.2f' % (accuracy_score(y_test, y_bagging)*100 , recall_score(y_test, y_bagging)*100 , (tn / (tn+fp))*100 , precision_score(y_test, y_bagging)*100 , f1_score(y_test, y_bagging)*100 ) )\n",
        "print('----------------------------------------------------')\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "adaBoost = AdaBoostClassifier()\n",
        "adaBoost = adaBoost.fit(X_train, y_train)\n",
        "y_adaboost = adaBoost.predict(X_test)\n",
        "tn, fp, fn, tp = confusion_matrix(y_test,y_adaboost).ravel()\n",
        "print('Performance Metrics of Test Data with scikit for AdaBoost Classifier: Accuracy : %0.2f , Recall : %0.2f ,  Specificity: %0.2f , Precision : %0.2f, F1 Score: %0.2f' % (accuracy_score(y_test, y_adaboost)*100 , recall_score(y_test, y_adaboost)*100 , (tn / (tn+fp))*100 , precision_score(y_test, y_adaboost)*100 , f1_score(y_test, y_adaboost)*100 ) )\n",
        "print('----------------------------------------------------')\n",
        "\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "gradientBoost = GradientBoostingClassifier()\n",
        "gradientBoost = gradientBoost.fit(X_train, y_train)\n",
        "y_gradientBoost = gradientBoost.predict(X_test)\n",
        "tn, fp, fn, tp = confusion_matrix(y_test,y_gradientBoost).ravel()\n",
        "print('Performance Metrics of Test Data with scikit for GradientBoosting Classifier: Accuracy : %0.2f , Recall : %0.2f , Specificity: %0.2f , Precision : %0.2f, F1 Score: %0.2f' % (accuracy_score(y_test, y_gradientBoost)*100 , recall_score(y_test, y_gradientBoost)*100 , (tn / (tn+fp))*100 ,  precision_score(y_test, y_gradientBoost)*100 , f1_score(y_test, y_gradientBoost)*100 ) )\n",
        "print('----------------------------------------------------')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "073mWCutDp6e",
        "outputId": "549c47e7-15ad-46bb-8756-d0c71172aba5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy: 96.662156\n",
            "Testing Accuracy: 96.529968\n",
            "Performance Metrics of Test Data : Accuracy : 96.53 , Recall : 96.16 ,Specificity: 96.93 , Precision : 97.14, F1 Score: 96.65\n",
            "----------------------------------------------------\n",
            "Performance Metrics of Test Data with scikit : Accuracy : 96.85 , Recall : 97.37 ,Specificity: 96.27 , Precision : 96.59, F1 Score: 96.98\n",
            "----------------------------------------------------\n",
            "Performance Metrics of Test Data with scikit for Random Forest: Accuracy : 98.21 , Recall : 97.98 , Specificity: 98.46 , Precision : 98.58, F1 Score: 98.28\n",
            "----------------------------------------------------\n",
            "Performance Metrics of Test Data with scikit for Bagging Classifier: Accuracy : 97.27 , Recall : 96.97 , Specificity: 97.59 , Precision : 97.76, F1 Score: 97.36\n",
            "----------------------------------------------------\n",
            "Performance Metrics of Test Data with scikit for AdaBoost Classifier: Accuracy : 97.48 , Recall : 97.78 ,  Specificity: 97.15 , Precision : 97.38, F1 Score: 97.58\n",
            "----------------------------------------------------\n",
            "Performance Metrics of Test Data with scikit for GradientBoosting Classifier: Accuracy : 97.69 , Recall : 97.37 , Specificity: 98.03 , Precision : 98.17, F1 Score: 97.77\n",
            "----------------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}